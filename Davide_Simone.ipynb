{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ae51def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244a0d2",
   "metadata": {},
   "source": [
    "# Phase 0 : exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b60081-2d42-42b7-bdea-d2c71426a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/simone/Downloads/spam.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea59ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                               Text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We drop the redundent looking columns\n",
    "unuseful = [\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"]\n",
    "df = df.drop(df[unuseful], axis=1)\n",
    "\n",
    "# We rename the columns in order to make them more understandable\n",
    "df.rename(columns = {\"v1\":\"Target\", \"v2\":\"Text\"}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7c2b0",
   "metadata": {},
   "source": [
    "# Phase 1: Data Preprocessing\n",
    "\n",
    "In order to further process the data, we need to make the data cleaner.\n",
    "\n",
    "In the first step we extract only the alphabetic characters, so we remove punctuation and numbers. Then we convert all the characters into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800b9939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/simone/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbfd5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process a text : clean, tokenize and stem each word in text\n",
    "def pre_processing(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # removing punctuation, lowercase the text, removing stopwords, map punctuation to space\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    p_text = text.translate(translator).lower()\n",
    "    ppt = \"\"\n",
    "    for word in p_text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            ppt += word + \" \"\n",
    "    text = ppt.strip(\" \")\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_sentence = []\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(lemmatizer.lemmatize(word, pos ='v'))\n",
    "    return ' '.join(stem_sentence)\n",
    "\n",
    "df[\"Pre_processed_text\"] = df[\"Text\"].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c260421-a825-4901-85ec-118a3af5bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it creates a list of all the words\n",
    "bag_words = set()\n",
    "for sms in df[\"Pre_processed_text\"]:\n",
    "    #print(sms)\n",
    "    for w in sms.split(\" \"):\n",
    "        if w != \"\":\n",
    "            bag_words = bag_words.union({w})\n",
    "bag = list(bag_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac60abc",
   "metadata": {},
   "source": [
    "# Phase 2: extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf1560d-5f7f-495c-9067-ef67f707d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it returns a list of words for each sms\n",
    "def split_words(text, bag_words):\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26e9ddcd-d07e-47c1-b0fe-0b03b2d58b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Words\"] = df[\"Pre_processed_text\"].apply(split_words, args = (bag_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9872d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pre_processed_text</th>\n",
       "      <th>Words</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think go usf live around though</td>\n",
       "      <td>[nah, think, go, usf, live, around, though]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>2nd time try 2 contact u u å£750 pound prize 2...</td>\n",
       "      <td>[2nd, time, try, 2, contact, u, u, å£750, poun...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>ì b go esplanade fr home</td>\n",
       "      <td>[ì, b, go, esplanade, fr, home]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitch act like interest buy something else...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, somethi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text  \\\n",
       "0       ham  Go until jurong point, crazy.. Available only ...   \n",
       "1       ham                      Ok lar... Joking wif u oni...   \n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       ham  U dun say so early hor... U c already then say...   \n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...     ...                                                ...   \n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568    ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569    ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570    ham  The guy did some bitching but I acted like i'd...   \n",
       "5571    ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                     Pre_processed_text  \\\n",
       "0     go jurong point crazy available bugis n great ...   \n",
       "1                                 ok lar joke wif u oni   \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                   u dun say early hor u c already say   \n",
       "4                   nah think go usf live around though   \n",
       "...                                                 ...   \n",
       "5567  2nd time try 2 contact u u å£750 pound prize 2...   \n",
       "5568                           ì b go esplanade fr home   \n",
       "5569                              pity mood suggestions   \n",
       "5570  guy bitch act like interest buy something else...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                                  Words  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4           [nah, think, go, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, try, 2, contact, u, u, å£750, poun...   \n",
       "5568                    [ì, b, go, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitch, act, like, interest, buy, somethi...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                 Vector  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "5567  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5568  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5569  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5570  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5571  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_len = len(bag)\n",
    "def vectorize_sms(words):\n",
    "    vector = np.zeros(bag_len,dtype=\"int64\")\n",
    "    for i in range(bag_len):\n",
    "        if bag[i] in words:\n",
    "            vector[i] += 1\n",
    "    return vector\n",
    "df[\"Vector\"] = df[\"Words\"].apply(vectorize_sms)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41984826-dfd2-46ad-97bc-b5bb85a17709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rupaul</th>\n",
       "      <th>rightly</th>\n",
       "      <th>evil</th>\n",
       "      <th>tscs08714740323</th>\n",
       "      <th>multiply</th>\n",
       "      <th>09050003091</th>\n",
       "      <th>ocean</th>\n",
       "      <th>anyone</th>\n",
       "      <th>49557</th>\n",
       "      <th>airtel</th>\n",
       "      <th>...</th>\n",
       "      <th>mising</th>\n",
       "      <th>headset</th>\n",
       "      <th>hard</th>\n",
       "      <th>goto</th>\n",
       "      <th>07880867867</th>\n",
       "      <th>09064012160</th>\n",
       "      <th>butt</th>\n",
       "      <th>o2fwd</th>\n",
       "      <th>fresh</th>\n",
       "      <th>african</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rupaul  rightly  evil  tscs08714740323  multiply  09050003091  ocean  \\\n",
       "0          0        0     0                0         0            0      0   \n",
       "1          0        0     0                0         0            0      0   \n",
       "2          0        0     0                0         0            0      0   \n",
       "3          0        0     0                0         0            0      0   \n",
       "4          0        0     0                0         0            0      0   \n",
       "...      ...      ...   ...              ...       ...          ...    ...   \n",
       "5567       0        0     0                0         0            0      0   \n",
       "5568       0        0     0                0         0            0      0   \n",
       "5569       0        0     0                0         0            0      0   \n",
       "5570       0        0     0                0         0            0      0   \n",
       "5571       0        0     0                0         0            0      0   \n",
       "\n",
       "      anyone  49557  airtel  ...  mising  headset  hard  goto  07880867867  \\\n",
       "0          0      0       0  ...       0        0     0     0            0   \n",
       "1          0      0       0  ...       0        0     0     0            0   \n",
       "2          0      0       0  ...       0        0     0     0            0   \n",
       "3          0      0       0  ...       0        0     0     0            0   \n",
       "4          0      0       0  ...       0        0     0     0            0   \n",
       "...      ...    ...     ...  ...     ...      ...   ...   ...          ...   \n",
       "5567       0      0       0  ...       0        0     0     0            0   \n",
       "5568       0      0       0  ...       0        0     0     0            0   \n",
       "5569       0      0       0  ...       0        0     0     0            0   \n",
       "5570       0      0       0  ...       0        0     0     0            0   \n",
       "5571       0      0       0  ...       0        0     0     0            0   \n",
       "\n",
       "      09064012160  butt  o2fwd  fresh  african  \n",
       "0               0     0      0      0        0  \n",
       "1               0     0      0      0        0  \n",
       "2               0     0      0      0        0  \n",
       "3               0     0      0      0        0  \n",
       "4               0     0      0      0        0  \n",
       "...           ...   ...    ...    ...      ...  \n",
       "5567            0     0      0      0        0  \n",
       "5568            0     0      0      0        0  \n",
       "5569            0     0      0      0        0  \n",
       "5570            0     0      0      0        0  \n",
       "5571            0     0      0      0        0  \n",
       "\n",
       "[5572 rows x 7644 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.zeros((len(df),bag_len),dtype=\"int64\")\n",
    "for i in range(len(df)):\n",
    "    X[i]+=df.iloc[i,4]\n",
    "pd.DataFrame(X,columns=bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7cce5d0a-277c-4652-8bc8-af906f0f9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros(len(df),dtype=\"int64\")\n",
    "for i in range(len(df[\"Target\"])):\n",
    "    if df.iloc[i,0]==\"ham\":\n",
    "        y[i]=0\n",
    "    else:\n",
    "        y[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65b7b857-2e37-4163-b13d-a3d85b587315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 7644), (4457,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "42c2b236-b015-46a1-b6fe-2ae2e84a2737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "N_yi = np.zeros((2, bag_len)) # feature count\n",
    "N_y = np.zeros((2)) # total count \n",
    "for i in range(len(y_train)):\n",
    "    # Compute N_y counting the features for each specific class\n",
    "    N_y[y_train[i]] += np.sum(X_train[i])\n",
    "    # Compute N_yi adding counting the specific words in each class\n",
    "    N_yi[y_train[i]] += (X_train[i])\n",
    "print(N_yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234190e9-6d43-4125-9acc-24bdd1191379",
   "metadata": {},
   "source": [
    "# Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9affc920-e056-4ea4-9349-ca5f59cf1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8660534 0.1339466]\n"
     ]
    }
   ],
   "source": [
    "P = np.zeros(2)\n",
    "classes=np.unique(y_train)\n",
    "# Implement Prior Probability P(A)\n",
    "for j in classes:\n",
    "    P[j] = np.count_nonzero(y_train == j)/(len(y_train))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2213a-b13c-4791-98f2-4dd54cbf914a",
   "metadata": {},
   "source": [
    "# Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "69a5edbc-9cc8-4bd4-8611-82ed0b45f828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.72653281e-05 6.72653281e-05 6.72653281e-05 ... 3.36326640e-05\n",
      "  6.72653281e-05 6.72653281e-05]\n",
      " [9.71062342e-05 9.71062342e-05 9.71062342e-05 ... 2.91318703e-04\n",
      "  9.71062342e-05 9.71062342e-05]]\n"
     ]
    }
   ],
   "source": [
    "posterior_matrix=np.zeros((2,bag_len))\n",
    "for i in range(bag_len):\n",
    "    for j in range(2):\n",
    "        posterior_matrix[j][i]=float((N_yi[j][i] + 1)/(N_y[j] + 2))\n",
    "print(posterior_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486738ca-afe8-4fa2-bc46-10673628e38e",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36070e-3f1c-495c-9d25-ecd984a733e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i in range(x.shape[0]):\n",
    "    tmp.append(posterior_(x[i], i, h, N_y, N_yi, n_features, alpha))\n",
    "    # Implement Likelihood\n",
    "    likelihood = float(np.prod(tmp))    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e73e2-4f0a-47a3-927c-04df2e7da4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix=np.zeros((len(X_train),2))\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(2):\n",
    "        likelihood_matrix[j][i]="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
