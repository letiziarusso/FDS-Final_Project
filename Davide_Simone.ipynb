{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae51def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244a0d2",
   "metadata": {},
   "source": [
    "# Phase 0 : exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b60081-2d42-42b7-bdea-d2c71426a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/simone/Downloads/spam.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea59ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target                                               Text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We drop the redundent looking columns\n",
    "unuseful = [\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"]\n",
    "df = df.drop(df[unuseful], axis=1)\n",
    "\n",
    "# We rename the columns in order to make them more understandable\n",
    "df.rename(columns = {\"v1\":\"Target\", \"v2\":\"Text\"}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7c2b0",
   "metadata": {},
   "source": [
    "# Phase 1: Data Preprocessing\n",
    "\n",
    "In order to further process the data, we need to make the data cleaner.\n",
    "\n",
    "In the first step we extract only the alphabetic characters, so we remove punctuation and numbers. Then we convert all the characters into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800b9939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/simone/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfd5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process a text : clean, tokenize and stem each word in text\n",
    "def pre_processing(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    # removing punctuation, lowercase the text, removing stopwords, map punctuation to space\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    p_text = text.translate(translator).lower()\n",
    "    ppt = \"\"\n",
    "    for word in p_text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            ppt += word + \" \"\n",
    "    text = ppt.strip(\" \")\n",
    "    token_words = word_tokenize(text)\n",
    "    lem_sentence = []\n",
    "    for word in token_words:\n",
    "        lem_sentence.append(lemmatizer.lemmatize(word, pos ='v'))\n",
    "    return ' '.join(lem_sentence)\n",
    "\n",
    "df[\"Pre_processed_text\"] = df[\"Text\"].apply(pre_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c260421-a825-4901-85ec-118a3af5bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it creates a list of all the words\n",
    "bag_words = set()\n",
    "for sms in df[\"Pre_processed_text\"]:\n",
    "    #print(sms)\n",
    "    for w in sms.split(\" \"):\n",
    "        if w != \"\":\n",
    "            bag_words = bag_words.union({w})\n",
    "bag = list(bag_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac60abc",
   "metadata": {},
   "source": [
    "# Phase 2: extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf1560d-5f7f-495c-9067-ef67f707d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it returns a list of words for each sms\n",
    "def split_words(text, bag_words):\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26e9ddcd-d07e-47c1-b0fe-0b03b2d58b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Words\"] = df[\"Pre_processed_text\"].apply(split_words, args = (bag_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9872d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pre_processed_text</th>\n",
       "      <th>Words</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think go usf live around though</td>\n",
       "      <td>[nah, think, go, usf, live, around, though]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>2nd time try 2 contact u u å£750 pound prize 2...</td>\n",
       "      <td>[2nd, time, try, 2, contact, u, u, å£750, poun...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>ì b go esplanade fr home</td>\n",
       "      <td>[ì, b, go, esplanade, fr, home]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitch act like interest buy something else...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, somethi...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target                                               Text  \\\n",
       "0       ham  Go until jurong point, crazy.. Available only ...   \n",
       "1       ham                      Ok lar... Joking wif u oni...   \n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       ham  U dun say so early hor... U c already then say...   \n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...     ...                                                ...   \n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568    ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569    ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570    ham  The guy did some bitching but I acted like i'd...   \n",
       "5571    ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                     Pre_processed_text  \\\n",
       "0     go jurong point crazy available bugis n great ...   \n",
       "1                                 ok lar joke wif u oni   \n",
       "2     free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                   u dun say early hor u c already say   \n",
       "4                   nah think go usf live around though   \n",
       "...                                                 ...   \n",
       "5567  2nd time try 2 contact u u å£750 pound prize 2...   \n",
       "5568                           ì b go esplanade fr home   \n",
       "5569                              pity mood suggestions   \n",
       "5570  guy bitch act like interest buy something else...   \n",
       "5571                                     rofl true name   \n",
       "\n",
       "                                                  Words  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4           [nah, think, go, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, try, 2, contact, u, u, å£750, poun...   \n",
       "5568                    [ì, b, go, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitch, act, like, interest, buy, somethi...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                 Vector  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "5567  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5568  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5569  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5570  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5571  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_len = len(bag)\n",
    "def vectorize_sms(words):\n",
    "    vector = np.zeros(bag_len,dtype=\"int64\")\n",
    "    for i in range(bag_len):\n",
    "        if bag[i] in words:\n",
    "            vector[i] += 1\n",
    "    return vector\n",
    "df[\"Vector\"] = df[\"Words\"].apply(vectorize_sms)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41984826-dfd2-46ad-97bc-b5bb85a17709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>p</th>\n",
       "      <th>freedom</th>\n",
       "      <th>academic</th>\n",
       "      <th>stereo</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>harri</th>\n",
       "      <th>describe</th>\n",
       "      <th>care</th>\n",
       "      <th>cdgt</th>\n",
       "      <th>...</th>\n",
       "      <th>clas</th>\n",
       "      <th>custcare</th>\n",
       "      <th>arent</th>\n",
       "      <th>buck</th>\n",
       "      <th>sayin</th>\n",
       "      <th>november</th>\n",
       "      <th>callon</th>\n",
       "      <th>ö´ó</th>\n",
       "      <th>truble</th>\n",
       "      <th>costå£3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      holiday  p  freedom  academic  stereo  bathroom  harri  describe  care  \\\n",
       "0           0  0        0         0       0         0      0         0     0   \n",
       "1           0  0        0         0       0         0      0         0     0   \n",
       "2           0  0        0         0       0         0      0         0     0   \n",
       "3           0  0        0         0       0         0      0         0     0   \n",
       "4           0  0        0         0       0         0      0         0     0   \n",
       "...       ... ..      ...       ...     ...       ...    ...       ...   ...   \n",
       "5567        0  0        0         0       0         0      0         0     0   \n",
       "5568        0  0        0         0       0         0      0         0     0   \n",
       "5569        0  0        0         0       0         0      0         0     0   \n",
       "5570        0  0        0         0       0         0      0         0     0   \n",
       "5571        0  0        0         0       0         0      0         0     0   \n",
       "\n",
       "      cdgt  ...  clas  custcare  arent  buck  sayin  november  callon  ö´ó  \\\n",
       "0        0  ...     0         0      0     0      0         0       0      0   \n",
       "1        0  ...     0         0      0     0      0         0       0      0   \n",
       "2        0  ...     0         0      0     0      0         0       0      0   \n",
       "3        0  ...     0         0      0     0      0         0       0      0   \n",
       "4        0  ...     0         0      0     0      0         0       0      0   \n",
       "...    ...  ...   ...       ...    ...   ...    ...       ...     ...    ...   \n",
       "5567     0  ...     0         0      0     0      0         0       0      0   \n",
       "5568     0  ...     0         0      0     0      0         0       0      0   \n",
       "5569     0  ...     0         0      0     0      0         0       0      0   \n",
       "5570     0  ...     0         0      0     0      0         0       0      0   \n",
       "5571     0  ...     0         0      0     0      0         0       0      0   \n",
       "\n",
       "      truble  costå£3  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "...      ...      ...  \n",
       "5567       0        0  \n",
       "5568       0        0  \n",
       "5569       0        0  \n",
       "5570       0        0  \n",
       "5571       0        0  \n",
       "\n",
       "[5572 rows x 7644 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.zeros((len(df),bag_len),dtype=\"int64\")\n",
    "for i in range(len(df)):\n",
    "    X[i]+=df.iloc[i,4]\n",
    "pd.DataFrame(X,columns=bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cce5d0a-277c-4652-8bc8-af906f0f9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros(len(df),dtype=\"int64\")\n",
    "for i in range(len(df[\"Target\"])):\n",
    "    if df.iloc[i,0]==\"ham\":\n",
    "        y[i]=0\n",
    "    else:\n",
    "        y[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b7b857-2e37-4163-b13d-a3d85b587315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 7644), (4457,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d3a26a2-30bc-4b8a-9211-e5dadb63e501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42c2b236-b015-46a1-b6fe-2ae2e84a2737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.  6.  2. ...  0.  1.  0.]\n",
      " [27.  3.  0. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "N_yi = np.zeros((2, bag_len)) # feature count\n",
    "N_y = np.zeros((2)) # total count \n",
    "for i in range(len(y_train)):\n",
    "    # Compute N_y counting the features for each specific class\n",
    "    N_y[y_train[i]] += np.sum(X_train[i])\n",
    "    # Compute N_yi adding counting the specific words in each class\n",
    "    N_yi[y_train[i]] += (X_train[i])\n",
    "print(N_yi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234190e9-6d43-4125-9acc-24bdd1191379",
   "metadata": {},
   "source": [
    "# Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9affc920-e056-4ea4-9349-ca5f59cf1aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8660534 0.1339466]\n"
     ]
    }
   ],
   "source": [
    "P = np.zeros(2)\n",
    "classes=np.unique(y_train)\n",
    "# Implement Prior Probability P(A)\n",
    "for j in classes:\n",
    "    P[j] = np.count_nonzero(y_train == j)/(len(y_train))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486738ca-afe8-4fa2-bc46-10673628e38e",
   "metadata": {},
   "source": [
    "# Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90a7c07c-0832-404d-9249-8c82147b9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "69a5edbc-9cc8-4bd4-8611-82ed0b45f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix_words=np.zeros((2,bag_len))\n",
    "for i in range(bag_len):\n",
    "    for j in range(2):\n",
    "        likelihood_matrix_words[j][i]=float((N_yi[j][i] + 1)/(N_y[j] + bag_len))\n",
    "likelihood_matrix_words=pd.DataFrame(likelihood_matrix_words,columns=bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f2883c0-cbe7-4bb7-a2b0-5cee07a07480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>p</th>\n",
       "      <th>freedom</th>\n",
       "      <th>academic</th>\n",
       "      <th>stereo</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>harri</th>\n",
       "      <th>describe</th>\n",
       "      <th>care</th>\n",
       "      <th>cdgt</th>\n",
       "      <th>...</th>\n",
       "      <th>clas</th>\n",
       "      <th>custcare</th>\n",
       "      <th>arent</th>\n",
       "      <th>buck</th>\n",
       "      <th>sayin</th>\n",
       "      <th>november</th>\n",
       "      <th>callon</th>\n",
       "      <th>ö´ó</th>\n",
       "      <th>truble</th>\n",
       "      <th>costå£3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 7644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    holiday         p   freedom  academic    stereo  bathroom     harri  \\\n",
       "0  0.000375  0.000187  0.000080  0.000054  0.000054  0.000054  0.000054   \n",
       "1  0.001561  0.000223  0.000056  0.000056  0.000056  0.000056  0.000056   \n",
       "\n",
       "   describe      care      cdgt  ...      clas  custcare     arent      buck  \\\n",
       "0  0.000054  0.001258  0.000027  ...  0.000054  0.000027  0.000054  0.000161   \n",
       "1  0.000056  0.000334  0.000167  ...  0.000056  0.000502  0.000056  0.000056   \n",
       "\n",
       "      sayin  november    callon     ö´ó    truble   costå£3  \n",
       "0  0.000054  0.000027  0.000054  0.000027  0.000054  0.000027  \n",
       "1  0.000056  0.000111  0.000056  0.000056  0.000056  0.000111  \n",
       "\n",
       "[2 rows x 7644 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_matrix_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "323e73e2-4f0a-47a3-927c-04df2e7da4eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood_matrix=np.zeros((len(X_train),2))\n",
    "for i in range(len(X_train)):\n",
    "    tmp_spam=[]\n",
    "    tmp_ham=[]\n",
    "    sms=X_train[i] #list of words\n",
    "    for index in range(len(sms)): #for each word in sms\n",
    "        if sms[index]!=0:\n",
    "            weight_ham,weight_spam=likelihood_matrix_words.iloc[:,index]\n",
    "            tmp_spam.append(math.log(weight_spam))\n",
    "            tmp_ham.append(math.log(weight_ham))\n",
    "    likelihood_matrix[i][0]=float(np.sum(tmp_ham))\n",
    "    likelihood_matrix[i][1]=float(np.sum(tmp_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "761cd371-81d9-40ff-9f77-4ee4077ceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix=pd.DataFrame(likelihood_matrix,columns=[\"ham\",\"spam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10c0d258-c6b0-429d-a213-286362e7eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-54.434155</td>\n",
       "      <td>-62.207409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-137.468846</td>\n",
       "      <td>-123.164313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-47.935712</td>\n",
       "      <td>-50.348928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-46.803153</td>\n",
       "      <td>-56.129671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-180.748513</td>\n",
       "      <td>-142.225845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>-53.888084</td>\n",
       "      <td>-66.716916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>-16.839779</td>\n",
       "      <td>-22.429726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>-50.434432</td>\n",
       "      <td>-57.382434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>-29.822265</td>\n",
       "      <td>-35.846948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>-17.910907</td>\n",
       "      <td>-21.760722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham        spam\n",
       "0     -54.434155  -62.207409\n",
       "1    -137.468846 -123.164313\n",
       "2     -47.935712  -50.348928\n",
       "3     -46.803153  -56.129671\n",
       "4    -180.748513 -142.225845\n",
       "...          ...         ...\n",
       "4452  -53.888084  -66.716916\n",
       "4453  -16.839779  -22.429726\n",
       "4454  -50.434432  -57.382434\n",
       "4455  -29.822265  -35.846948\n",
       "4456  -17.910907  -21.760722\n",
       "\n",
       "[4457 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e2ec95c-3834-440a-993f-4dc4e4677bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix[\"ham\"] = likelihood_matrix[\"ham\"]+math.log(P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dbaa6d72-8f82-45a4-b7c0-fabfa4fc7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix[\"spam\"] = likelihood_matrix[\"spam\"]+math.log(P[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5e1d637-7c7b-42ef-9117-73158b3f9fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-54.577964</td>\n",
       "      <td>-64.217723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-137.612654</td>\n",
       "      <td>-125.174627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48.079520</td>\n",
       "      <td>-52.359242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-46.946962</td>\n",
       "      <td>-58.139986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-180.892322</td>\n",
       "      <td>-144.236159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-53.850110</td>\n",
       "      <td>-62.859600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-35.791139</td>\n",
       "      <td>-35.178199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-49.437304</td>\n",
       "      <td>-59.392749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-11.986493</td>\n",
       "      <td>-18.267686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-47.172168</td>\n",
       "      <td>-54.710617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ham        spam\n",
       "0  -54.577964  -64.217723\n",
       "1 -137.612654 -125.174627\n",
       "2  -48.079520  -52.359242\n",
       "3  -46.946962  -58.139986\n",
       "4 -180.892322 -144.236159\n",
       "5  -53.850110  -62.859600\n",
       "6  -35.791139  -35.178199\n",
       "7  -49.437304  -59.392749\n",
       "8  -11.986493  -18.267686\n",
       "9  -47.172168  -54.710617"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_matrix.iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef963e81-1605-4731-b330-d54fa23b5086",
   "metadata": {},
   "source": [
    "\n",
    "ham\n",
    "ham\n",
    "spam\n",
    "ham\n",
    "ham\n",
    "spam\n",
    "ham\n",
    "ham\n",
    "spam\n",
    "spam\n",
    "ham\n",
    "spam\n",
    "spam\n",
    "ham\n",
    "ham\n",
    "spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0a857-2b8e-471b-ab98-42810ee44415",
   "metadata": {},
   "source": [
    "## Non funziona nulla!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06578da5-664a-47f9-97fd-2f02f5dcf6a7",
   "metadata": {},
   "source": [
    "Letizia propone di usare il pacchetto, ma io sono stronzo e non voglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a08307-e60a-4999-ab5d-a5794d235097",
   "metadata": {},
   "source": [
    "Abbiamo provato anche come diceva Franceseca, ci metteva troppo e sembrava non funzionare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e102785-df06-4327-adb3-7d13d2e53473",
   "metadata": {},
   "source": [
    "Se avete idee, ditelo che qua siamo disperati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293428e1-9362-4c0f-a2f0-4fd9f7fc9c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
